{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('monkeypox.csv')\n",
    "df = df.values\n",
    "\n",
    "x = df[:, 1:-1]\n",
    "y = df[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in range(1, 10):\n",
    "    df[:, i] = le.fit_transform(df[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = [] \n",
    "y_test = []\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuration rate for Bernoulli Naive Bayes:\n",
      "Train size 0.5 = 67.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "print(\"Accuration rate for Bernoulli Naive Bayes:\")\n",
    "bnb.fit(x_train, y_train)\n",
    "y_predict = bnb.predict(x_test)\n",
    "error = ((y_test != y_predict).sum()/len(y_predict)*100)\n",
    "akurasi = str(100 - error) + \"%\"\n",
    "print(f\"Train size 0.5 =\", akurasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.38      0.18      0.25      4550\n",
      "    Negative       0.64      0.83      0.72      7950\n",
      "\n",
      "    accuracy                           0.60     12500\n",
      "   macro avg       0.51      0.51      0.49     12500\n",
      "weighted avg       0.55      0.60      0.55     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Positive', 'Negative']\n",
    "\n",
    "print(classification_report(y_train, y_predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6626 0.674  0.6742 0.6788 0.6756]\n",
      "Akurasi Algoritma Bernoulli =  67.304%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold_validation = KFold(5)\n",
    "\n",
    "print(cross_val_score(bnb, x, y, cv=kfold_validation))\n",
    "result = cross_val_score(bnb, x, y, cv=kfold_validation).mean()\n",
    "akurasi = str(result * 100) + \"%\"\n",
    "print(\"Akurasi Algoritma Bernoulli = \", akurasi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 67.44 %\n",
      "Precision = 64.8084188853207 %\n",
      "Recall =  59.24794488069347 %\n",
      "F1 score =  58.623780163975894 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)*100\n",
    "precision = precision_score(y_test, y_predict, average=\"macro\", zero_division=0)*100\n",
    "recall = recall_score(y_test, y_predict, average='macro', zero_division=0)*100\n",
    "f1score = f1_score(y_test, y_predict, average='macro', zero_division=0)*100\n",
    "\n",
    "print('Accuracy =', accuracy, \"%\")\n",
    "print('Precision =', precision, \"%\")\n",
    "print('Recall = ', recall, \"%\")\n",
    "print('F1 score = ', f1score, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e7257ba9fbb507c8ead2d5fd05e7903ce4453e351a1d93c8a0f64cb3a676180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
